{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f844c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Specify the full path to mnist.pkl\n",
    "file_path = './data/mnist.pkl'\n",
    "\n",
    "# Load the MNIST dataset from the saved file\n",
    "with open(file_path, 'rb') as f:\n",
    "    mnist_data = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644c61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(inp):\n",
    "    \"\"\"\n",
    "    Normalizes image pixels here to have 0 mean and unit variance.\n",
    "\n",
    "    args:\n",
    "        inp : N X d 2D array where N is the number of examples and d is the number of dimensions\n",
    "\n",
    "    returns:\n",
    "        normalized inp: N X d 2D array\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "def normalize_data(inp):\n",
    "    mean = np.mean(inp, axis=0)\n",
    "    std = np.std(inp, axis=0)\n",
    "    import warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        normalized_inp = np.where(std == 0, 0, (inp - mean) / std)\n",
    "    return normalized_inp\n",
    "\n",
    "\n",
    "def one_hot_encoding(labels, num_classes=10):\n",
    "    \"\"\"\n",
    "    Encodes labels using one hot encoding.\n",
    "\n",
    "    args:\n",
    "        labels : N dimensional 1D array where N is the number of examples\n",
    "        num_classes: Number of distinct labels that we have (10 for MNIST)\n",
    "\n",
    "    returns:\n",
    "        oneHot : N X num_classes 2D array\n",
    "    \"\"\"\n",
    "    return np.eye(num_classes)[labels.flatten()]\n",
    "\n",
    "def load_data(data):\n",
    "    \"\"\"\n",
    "    Loads, splits our dataset - MNIST into train, val and test sets and normalizes them\n",
    "\n",
    "    args:\n",
    "        path: Path to MNIST dataset\n",
    "    returns:\n",
    "        train_normalized_images, train_one_hot_labels, val_normalized_images, val_one_hot_labels,  test_normalized_images, test_one_hot_labels\n",
    "\n",
    "    \"\"\"\n",
    " \n",
    "\n",
    "    train_images, train_labels, test_images, test_labels = data\n",
    "\n",
    "\n",
    "    # Reformat the images and labels\n",
    "    train_images, test_images = train_images.reshape(train_images.shape[0], -1), test_images.reshape(test_images.shape[0], -1)\n",
    "    train_labels, test_labels = np.expand_dims(train_labels, axis=1), np.expand_dims(test_labels, axis=1)\n",
    "    print('Reformatting done.')\n",
    "    print(f'Shape:  train {train_images.shape}, test {test_images.shape}')\n",
    "    print(f'Shape:  train {train_labels.shape}, test {test_labels.shape}')\n",
    "\n",
    "    # Create 80-20 train-validation split\n",
    "    train_images, train_labels, val_images, val_labels = createTrainValSplit(train_images, train_labels)\n",
    "    print('Splitting train and validation done.')\n",
    "\n",
    "    # Preprocess data\n",
    "    train_normalized_images = normalize_data(train_images)\n",
    "    train_one_hot_labels = one_hot_encoding(train_labels, num_classes=10)  # (n, 10)\n",
    "\n",
    "    val_normalized_images = normalize_data(val_images)\n",
    "    val_one_hot_labels = one_hot_encoding(val_labels, num_classes=10)  # (n, 10)\n",
    "\n",
    "    test_normalized_images = normalize_data(test_images)\n",
    "    test_one_hot_labels = one_hot_encoding(test_labels, num_classes=10)  # (n, 10)\n",
    "\n",
    "    return train_normalized_images, train_one_hot_labels, val_normalized_images, val_one_hot_labels, test_normalized_images, test_one_hot_labels\n",
    "\n",
    "def createTrainValSplit(x_train,y_train):\n",
    "\n",
    "    \"\"\"\n",
    "    Creates the train-validation split (80-20 split for train-val). Please shuffle the data before creating the train-val split.\n",
    "    \"\"\"\n",
    "    assert len(x_train) == len(y_train)\n",
    "    indices = np.arange(len(x_train))\n",
    "    np.random.shuffle(indices)\n",
    "    x_train_shuffled = x_train[indices]\n",
    "    y_train_shuffled = y_train[indices]\n",
    "    split_index = int(0.8 * len(x_train))\n",
    "\n",
    "    x_train_split = x_train_shuffled[:split_index]\n",
    "    y_train_split = y_train_shuffled[:split_index]\n",
    "    x_val_split = x_train_shuffled[split_index:]\n",
    "    y_val_split = y_train_shuffled[split_index:]\n",
    "\n",
    "    return x_train_split, y_train_split, x_val_split, y_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "314de9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libra/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reformatting done.\n",
      "Shape:  train (60000, 784), test (10000, 784)\n",
      "Shape:  train (60000, 1), test (10000, 1)\n",
      "Splitting train and validation done.\n",
      "Validation Accuracy: 0.66925\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83      1193\n",
      "           1       0.80      0.24      0.37      1346\n",
      "           2       0.63      0.79      0.70      1189\n",
      "           3       0.74      0.83      0.79      1189\n",
      "           4       0.50      0.86      0.64      1136\n",
      "           5       0.71      0.76      0.74      1086\n",
      "           6       0.81      0.87      0.84      1248\n",
      "           7       0.53      0.36      0.43      1288\n",
      "           8       0.65      0.70      0.68      1163\n",
      "           9       0.66      0.44      0.53      1162\n",
      "\n",
      "    accuracy                           0.67     12000\n",
      "   macro avg       0.68      0.68      0.65     12000\n",
      "weighted avg       0.68      0.67      0.65     12000\n",
      "\n",
      "Test Accuracy: 0.6123\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86       980\n",
      "           1       0.72      0.34      0.46      1135\n",
      "           2       0.65      0.82      0.73      1032\n",
      "           3       0.66      0.81      0.73      1010\n",
      "           4       0.66      0.37      0.48       982\n",
      "           5       0.61      0.81      0.69       892\n",
      "           6       0.75      0.80      0.77       958\n",
      "           7       0.72      0.29      0.41      1028\n",
      "           8       0.35      0.73      0.47       974\n",
      "           9       0.55      0.28      0.38      1009\n",
      "\n",
      "    accuracy                           0.61     10000\n",
      "   macro avg       0.64      0.62      0.60     10000\n",
      "weighted avg       0.65      0.61      0.59     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Ensure the preprocessing functions and load_data are defined in your notebook\n",
    "\n",
    "# Load and preprocess the data\n",
    "x_train, y_train, x_valid, y_valid, x_test, y_test = load_data(mnist_data)\n",
    "\n",
    "# One-hot encoding is not necessary for Decision Tree classifier with scikit-learn\n",
    "# Scikit-learn's Decision Tree can handle multi-class labels without one-hot encoding\n",
    "# We use the labels directly\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_valid = np.argmax(y_valid, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_valid_pred = clf.predict(x_valid)\n",
    "\n",
    "# Calculate accuracy on validation data\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_pred)\n",
    "\n",
    "# Print the classification report for precision, recall, f1-score on validation data\n",
    "valid_report = classification_report(y_valid, y_valid_pred)\n",
    "\n",
    "# Print the validation results\n",
    "print(\"Validation Accuracy:\", valid_accuracy)\n",
    "print(\"Validation Classification Report:\")\n",
    "print(valid_report)\n",
    "\n",
    "# After tuning on validation data, evaluate on test data\n",
    "y_test_pred = clf.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "# Print the test results\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test Classification Report:\")\n",
    "print(test_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "595e178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Validation Accuracy: 0.9641666666666666\n",
      "Random Forest Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1193\n",
      "           1       0.99      0.99      0.99      1346\n",
      "           2       0.95      0.96      0.96      1189\n",
      "           3       0.95      0.96      0.95      1189\n",
      "           4       0.95      0.97      0.96      1136\n",
      "           5       0.96      0.95      0.96      1086\n",
      "           6       0.98      0.98      0.98      1248\n",
      "           7       0.98      0.94      0.96      1288\n",
      "           8       0.95      0.95      0.95      1163\n",
      "           9       0.94      0.94      0.94      1162\n",
      "\n",
      "    accuracy                           0.96     12000\n",
      "   macro avg       0.96      0.96      0.96     12000\n",
      "weighted avg       0.96      0.96      0.96     12000\n",
      "\n",
      "Random Forest Test Accuracy: 0.9549\n",
      "Random Forest Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       980\n",
      "           1       0.99      0.98      0.99      1135\n",
      "           2       0.95      0.95      0.95      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.92      0.96      0.94       892\n",
      "           6       0.98      0.95      0.96       958\n",
      "           7       0.98      0.91      0.95      1028\n",
      "           8       0.92      0.95      0.94       974\n",
      "           9       0.95      0.93      0.94      1009\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.96      0.95      0.95     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_valid_pred_rf = rf_clf.predict(x_valid)\n",
    "\n",
    "# Calculate accuracy on validation data\n",
    "valid_accuracy_rf = accuracy_score(y_valid, y_valid_pred_rf)\n",
    "\n",
    "# Print the classification report for precision, recall, f1-score on validation data\n",
    "valid_report_rf = classification_report(y_valid, y_valid_pred_rf)\n",
    "\n",
    "# Print the validation results for Random Forest\n",
    "print(\"Random Forest Validation Accuracy:\", valid_accuracy_rf)\n",
    "print(\"Random Forest Validation Classification Report:\")\n",
    "print(valid_report_rf)\n",
    "\n",
    "# After tuning on validation data, evaluate on test data\n",
    "y_test_pred_rf = rf_clf.predict(x_test)\n",
    "test_accuracy_rf = accuracy_score(y_test, y_test_pred_rf)\n",
    "test_report_rf = classification_report(y_test, y_test_pred_rf)\n",
    "\n",
    "# Print the test results for Random Forest\n",
    "print(\"Random Forest Test Accuracy:\", test_accuracy_rf)\n",
    "print(\"Random Forest Test Classification Report:\")\n",
    "print(test_report_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e871c4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Accuracy based on Label Frequency Distribution: 0.11241666666666666\n"
     ]
    }
   ],
   "source": [
    "def expected_label_distribution_accuracy(train_labels):\n",
    "    \"\"\"\n",
    "    Calculate the expected accuracy based on the label frequency distribution in the training set.\n",
    "    This is essentially the accuracy we would expect if we always predicted the most frequent label.\n",
    "    \"\"\"\n",
    "    _, counts = np.unique(train_labels, return_counts=True)\n",
    "    expected_accuracy = np.max(counts) / np.sum(counts)\n",
    "    return expected_accuracy\n",
    "\n",
    "# Calculate the expected accuracy based on training label distribution\n",
    "expected_accuracy = expected_label_distribution_accuracy(y_train)\n",
    "\n",
    "# Print the expected accuracy\n",
    "print(f\"Expected Accuracy based on Label Frequency Distribution: {expected_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "752022e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Validation Accuracy: 0.4136666666666667\n",
      "Neural Network Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.08      0.13      1193\n",
      "           1       0.44      0.89      0.59      1346\n",
      "           2       0.22      0.14      0.17      1189\n",
      "           3       0.30      0.45      0.36      1189\n",
      "           4       0.44      0.60      0.50      1136\n",
      "           5       0.00      0.00      0.00      1086\n",
      "           6       0.38      0.89      0.54      1248\n",
      "           7       0.71      0.62      0.66      1288\n",
      "           8       0.00      0.00      0.00      1163\n",
      "           9       0.46      0.32      0.38      1162\n",
      "\n",
      "    accuracy                           0.41     12000\n",
      "   macro avg       0.33      0.40      0.33     12000\n",
      "weighted avg       0.34      0.41      0.34     12000\n",
      "\n",
      "Neural Network Test Accuracy: 0.4041\n",
      "Neural Network Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.06      0.10       980\n",
      "           1       0.44      0.90      0.59      1135\n",
      "           2       0.20      0.13      0.16      1032\n",
      "           3       0.32      0.46      0.38      1010\n",
      "           4       0.42      0.57      0.49       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.36      0.91      0.52       958\n",
      "           7       0.67      0.60      0.63      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.42      0.32      0.36      1009\n",
      "\n",
      "    accuracy                           0.40     10000\n",
      "   macro avg       0.32      0.39      0.32     10000\n",
      "weighted avg       0.32      0.40      0.33     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/libra/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/libra/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/libra/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/libra/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/libra/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/libra/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Initialize a simple Multi-Layer Perceptron (neural network) classifier\n",
    "# We'll start with a single hidden layer with 50 neurons, which is a good starting point.\n",
    "# 'relu' activation function and 'adam' optimizer are commonly used and good defaults.\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(1,), activation='relu', solver='adam', random_state=0)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "mlp_clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_valid_pred_mlp = mlp_clf.predict(x_valid)\n",
    "\n",
    "# Calculate accuracy on validation data\n",
    "valid_accuracy_mlp = accuracy_score(y_valid, y_valid_pred_mlp)\n",
    "\n",
    "# Print the classification report for precision, recall, f1-score on validation data\n",
    "valid_report_mlp = classification_report(y_valid, y_valid_pred_mlp)\n",
    "\n",
    "# Print the validation results for the neural network\n",
    "print(\"Neural Network Validation Accuracy:\", valid_accuracy_mlp)\n",
    "print(\"Neural Network Validation Classification Report:\")\n",
    "print(valid_report_mlp)\n",
    "\n",
    "# After tuning on validation data, evaluate on test data\n",
    "y_test_pred_mlp = mlp_clf.predict(x_test)\n",
    "test_accuracy_mlp = accuracy_score(y_test, y_test_pred_mlp)\n",
    "test_report_mlp = classification_report(y_test, y_test_pred_mlp)\n",
    "\n",
    "# Print the test results for the neural network\n",
    "print(\"Neural Network Test Accuracy:\", test_accuracy_mlp)\n",
    "print(\"Neural Network Test Classification Report:\")\n",
    "print(test_report_mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07e9c4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Validation Accuracy: 0.9764166666666667\n",
      "Neural Network Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1193\n",
      "           1       0.99      0.99      0.99      1346\n",
      "           2       0.97      0.97      0.97      1189\n",
      "           3       0.97      0.97      0.97      1189\n",
      "           4       0.97      0.98      0.98      1136\n",
      "           5       0.97      0.97      0.97      1086\n",
      "           6       0.98      0.98      0.98      1248\n",
      "           7       0.98      0.97      0.98      1288\n",
      "           8       0.97      0.97      0.97      1163\n",
      "           9       0.97      0.97      0.97      1162\n",
      "\n",
      "    accuracy                           0.98     12000\n",
      "   macro avg       0.98      0.98      0.98     12000\n",
      "weighted avg       0.98      0.98      0.98     12000\n",
      "\n",
      "Neural Network Test Accuracy: 0.9772\n",
      "Neural Network Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.97      0.97      0.97      1032\n",
      "           3       0.97      0.98      0.98      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.98      0.98      0.98       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.97      0.97      0.97      1028\n",
      "           8       0.97      0.97      0.97       974\n",
      "           9       0.97      0.96      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Initialize a simple Multi-Layer Perceptron (neural network) classifier\n",
    "# We'll start with a single hidden layer with 50 neurons, which is a good starting point.\n",
    "# 'relu' activation function and 'adam' optimizer are commonly used and good defaults.\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(512,), activation='relu', solver='adam', random_state=0)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "mlp_clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_valid_pred_mlp = mlp_clf.predict(x_valid)\n",
    "\n",
    "# Calculate accuracy on validation data\n",
    "valid_accuracy_mlp = accuracy_score(y_valid, y_valid_pred_mlp)\n",
    "\n",
    "# Print the classification report for precision, recall, f1-score on validation data\n",
    "valid_report_mlp = classification_report(y_valid, y_valid_pred_mlp)\n",
    "\n",
    "# Print the validation results for the neural network\n",
    "print(\"Neural Network Validation Accuracy:\", valid_accuracy_mlp)\n",
    "print(\"Neural Network Validation Classification Report:\")\n",
    "print(valid_report_mlp)\n",
    "\n",
    "# After tuning on validation data, evaluate on test data\n",
    "y_test_pred_mlp = mlp_clf.predict(x_test)\n",
    "test_accuracy_mlp = accuracy_score(y_test, y_test_pred_mlp)\n",
    "test_report_mlp = classification_report(y_test, y_test_pred_mlp)\n",
    "\n",
    "# Print the test results for the neural network\n",
    "print(\"Neural Network Test Accuracy:\", test_accuracy_mlp)\n",
    "print(\"Neural Network Test Classification Report:\")\n",
    "print(test_report_mlp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a1efe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
